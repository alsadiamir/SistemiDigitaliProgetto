{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up simple CNN for MNIST hand-written digits image recognition\n",
    "#import the necessary libraries \n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9a369a8280>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAM70lEQVR4nO3db6hU953H8c8nyfVBohBdLyIaYrf4JH9Y21zMYpNiaLYk5oHpE6OE4oawNpBACyWsmAeGmEAStm2ELIJuQnXpphRaEx+EjYmUSAkpuQY3msRWNygqRkd8YBoQN9fvPrjHcmvunLnOOTNn9Pt+wTAz53vOnC8HP56Z85u5P0eEAFz9rmm6AQD9QdiBJAg7kARhB5Ig7EAS1/VzZ7Nnz44FCxb0c5dAKocPH9bp06c9Wa1S2G3fJ2mjpGsl/UdEPF+2/oIFCzQ6OlpllwBKjIyMtK11/Tbe9rWS/l3S/ZJukbTK9i3dvh6A3qrymX2xpEMR8VlEnJf0a0nL62kLQN2qhH2epKMTnh8rlv0N22tsj9oebbVaFXYHoIqeX42PiM0RMRIRI8PDw73eHYA2qoT9uKSbJjyfXywDMICqhP0DSQttf8P2NEkrJe2opy0Adet66C0ivrL9hKS3ND709mpEfFxbZwBqVWmcPSLelPRmTb0A6CG+LgskQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IotKUzbYPS/pC0pikryJipI6mANSvUtgL90TE6RpeB0AP8TYeSKJq2EPSTtt7bK+ZbAXba2yP2h5ttVoVdwegW1XDfldEfFvS/ZIet/3dS1eIiM0RMRIRI8PDwxV3B6BblcIeEceL+1OStktaXEdTAOrXddht32B7xsXHkr4vaX9djQGoV5Wr8XMkbbd98XX+KyL+u5aucMU4dOhQaf3s2bNta8eOHSvd9sknnyytP/PMM6X1hx56qLSeTddhj4jPJP1Djb0A6CGG3oAkCDuQBGEHkiDsQBKEHUiijh/CoIMzZ86U1l944YXS+qZNm+psp1Zffvllaf3ChQt96gSdcGYHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZ++DnTt3ltZffPHF0vqsWbNK67feeutl93TRwoULS+sHDx4srd9+++2l9SVLlrStvfzyy6Xbvv/++6V1XB7O7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOPsffDAAw+U1u+8887S+tjYWGn93XffbVsr/tT3QNq9e3dpvdM4+4033lhjN1c/zuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7H0wY8aM0vo777xTWt+4cWNpPSLa1poeZy/r7dy5c6XbDg0NldbvvvvurnrKquOZ3fartk/Z3j9h2Szbb9s+WNzP7G2bAKqaytv4X0q675JlayXtioiFknYVzwEMsI5hj4jdki6dv2i5pK3F462SHqy3LQB16/YC3ZyIOFE8/lzSnHYr2l5je9T2aKvV6nJ3AKqqfDU+xq/AtL0KExGbI2IkIkaGh4er7g5Al7oN+0nbcyWpuD9VX0sAeqHbsO+QtLp4vFrSG/W0A6BXOo6z235N0lJJs20fk7Re0vOSfmP7UUlHJK3oZZNXu+nTp5fWn3rqqT51Ur/Tp0+3rW3btq1023Xr1pXWr7/++q56yqpj2CNiVZvS92ruBUAP8XVZIAnCDiRB2IEkCDuQBGEHkuAnruip7du3d73t0qVL62sEnNmBLAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2VHJ+fPnS+vPPvts29rcuXNLt73nnnu66gmT48wOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzo5K1q9fX1o/evRo29rateXzgV53Hf8868SZHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYCATpcbGxkrru3fv7vq1H3744a63xeXreGa3/artU7b3T1j2tO3jtvcWt2W9bRNAVVN5G/9LSfdNsvwXEbGouL1Zb1sA6tYx7BGxW9KZPvQCoIeqXKB7wvZHxdv8me1Wsr3G9qjt0VarVWF3AKroNuybJH1T0iJJJyT9rN2KEbE5IkYiYmR4eLjL3QGoqquwR8TJiBiLiAuStkhaXG9bAOrWVdhtT/wbwD+QtL/dugAGQ8dxdtuvSVoqabbtY5LWS1pqe5GkkHRY0o961yKatG/fvtL6e++9V1pfsmRJ29ptt93WVU/oTsewR8SqSRa/0oNeAPQQX5cFkiDsQBKEHUiCsANJEHYgCX7iilIbNmyotP0jjzxSUyeoijM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOHty586dK63v2bOntD5t2rTS+rJl/OHhQcGZHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJw9uQMHDpTWjxw5UlofGhoqrV+4cOGye0JvcGYHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZ7/Kdfq9+tq1ayu9/ooVK0rr8+fPr/T6qE/HM7vtm2z/3vYntj+2/eNi+Szbb9s+WNzP7H27ALo1lbfxX0n6aUTcIukfJT1u+xZJayXtioiFknYVzwEMqI5hj4gTEfFh8fgLSZ9KmidpuaStxWpbJT3Yox4B1OCyLtDZXiDpW5L+KGlORJwoSp9LmtNmmzW2R22PtlqtKr0CqGDKYbc9XdJvJf0kIs5OrEVESIrJtouIzRExEhEjw8PDlZoF0L0phd32kMaD/quI+F2x+KTtuUV9rqRTvWkRQB06Dr3ZtqRXJH0aET+fUNohabWk54v7N3rSISp56aWXSutvvfVWab3Tn4p+7rnnLrclNGQq4+zfkfRDSfts7y2WrdN4yH9j+1FJRySVD7gCaFTHsEfEHyS5Tfl79bYDoFf4uiyQBGEHkiDsQBKEHUiCsANJ8BPXq8DRo0fb1jqNs3fy+uuvl9ZvvvnmSq+P/uHMDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM5+FdiwYUPb2smTJ0u3Xb16dWn93nvv7aonDB7O7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOPsV4ADBw6U1rds2dL1az/22GOl9aGhoa5fG4OFMzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJDGV+dlvkrRN0hxJIWlzRGy0/bSkf5HUKlZdFxFv9qrRzObNm1dav+aa9v9nr1y5snTbO+64o6uecOWZypdqvpL004j40PYMSXtsv13UfhER/9a79gDUZSrzs5+QdKJ4/IXtTyWVn2oADJzL+sxue4Gkb0n6Y7HoCdsf2X7V9sw226yxPWp7tNVqTbYKgD6YcthtT5f0W0k/iYizkjZJ+qakRRo/8/9ssu0iYnNEjETEyPDwcPWOAXRlSmG3PaTxoP8qIn4nSRFxMiLGIuKCpC2SFveuTQBVdQy7bUt6RdKnEfHzCcvnTljtB5L2198egLpM5Wr8dyT9UNI+23uLZeskrbK9SOPDcYcl/agH/UHSjBkzSutjY2N96gRXsqlcjf+DJE9SYkwduILwDTogCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjoj+7cxuSToyYdFsSaf71sDlGdTeBrUvid66VWdvN0fEpH//ra9h/9rO7dGIGGmsgRKD2tug9iXRW7f61Rtv44EkCDuQRNNh39zw/ssMam+D2pdEb93qS2+NfmYH0D9Nn9kB9AlhB5JoJOy277P9J9uHbK9tood2bB+2vc/2XtujDffyqu1TtvdPWDbL9tu2Dxb3k86x11BvT9s+Xhy7vbaXNdTbTbZ/b/sT2x/b/nGxvNFjV9JXX45b3z+z275W0p8l/ZOkY5I+kLQqIj7payNt2D4saSQiGv8Chu3vSvqLpG0RcVux7EVJZyLi+eI/ypkR8a8D0tvTkv7S9DTexWxFcydOMy7pQUn/rAaPXUlfK9SH49bEmX2xpEMR8VlEnJf0a0nLG+hj4EXEbklnLlm8XNLW4vFWjf9j6bs2vQ2EiDgRER8Wj7+QdHGa8UaPXUlffdFE2OdJOjrh+TEN1nzvIWmn7T221zTdzCTmRMSJ4vHnkuY02cwkOk7j3U+XTDM+MMeum+nPq+IC3dfdFRHflnS/pMeLt6sDKcY/gw3S2OmUpvHul0mmGf+rJo9dt9OfV9VE2I9LumnC8/nFsoEQEceL+1OStmvwpqI+eXEG3eL+VMP9/NUgTeM92TTjGoBj1+T0502E/QNJC21/w/Y0SSsl7Wigj6+xfUNx4US2b5D0fQ3eVNQ7JK0uHq+W9EaDvfyNQZnGu90042r42DU+/XlE9P0maZnGr8j/r6SnmuihTV9/L+l/itvHTfcm6TWNv637P41f23hU0t9J2iXpoKR3JM0aoN7+U9I+SR9pPFhzG+rtLo2/Rf9I0t7itqzpY1fSV1+OG1+XBZLgAh2QBGEHkiDsQBKEHUiCsANJEHYgCcIOJPH//abjWFW6MBcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "image_index = 258 # You may select anything up to 60,000\n",
    "print(y_train[image_index]) # The label \n",
    "plt.imshow(x_train[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the shape of the imput elements\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing the required Keras modules containing model and layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Sequential Model and adding the layers\n",
    "#layerconv = Conv2D(28, kernel_size=(3,3), input_shape=input_shape)\n",
    "#print(layerconv.kernel)\n",
    "#print(layerconv.kernel_initializer.seed)\n",
    "#print(\"*******\")\n",
    "#layerconv = Dropout(0.2)\n",
    "#print(layerconv.strides)\n",
    "#print(layerconv.kernel_initializer)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 67s 35ms/step - loss: 0.3630 - accuracy: 0.8879 - categorical_accuracy: 0.1004\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 59s 31ms/step - loss: 0.1350 - accuracy: 0.9592 - categorical_accuracy: 0.1009\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 57s 30ms/step - loss: 0.1011 - accuracy: 0.9687 - categorical_accuracy: 0.0995\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 61s 33ms/step - loss: 0.0859 - accuracy: 0.9715 - categorical_accuracy: 0.0996\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 62s 33ms/step - loss: 0.0740 - accuracy: 0.9765 - categorical_accuracy: 0.1008\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 55s 29ms/step - loss: 0.0621 - accuracy: 0.9797 - categorical_accuracy: 0.0974\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 50s 27ms/step - loss: 0.0544 - accuracy: 0.9812 - categorical_accuracy: 0.0982\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0512 - accuracy: 0.9835 - categorical_accuracy: 0.0987\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0433 - accuracy: 0.9852 - categorical_accuracy: 0.1000\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0417 - accuracy: 0.9865 - categorical_accuracy: 0.1002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f99ffdfdfd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x=x_train,y=y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.33707282e-02  1.52421936e-01  7.19589069e-02  1.18475944e-01\n",
      "  2.09078997e-01 -1.59713905e-04  5.49072064e-02  2.26145044e-01\n",
      " -5.99051937e-02  5.62260039e-02 -5.64086065e-02  1.95738688e-01\n",
      "  7.87821636e-02 -6.13306239e-02  1.91300184e-01 -4.09449309e-01\n",
      "  9.62096006e-02  1.54509261e-01 -1.25701070e-01  6.55530095e-02\n",
      " -2.73726042e-02 -1.67272002e-01 -4.95562851e-02 -1.78888097e-01\n",
      "  1.62901998e-01  2.88374051e-02  1.74398020e-01  7.06249028e-02]\n"
     ]
    }
   ],
   "source": [
    "#Code to get the output of network layers\n",
    "\n",
    "inp = model.input                                           # input placeholder\n",
    "outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
    "functors = [K.function([inp], [out]) for out in outputs]    # evaluation functions\n",
    "\n",
    "# Testing\n",
    "test = np.random.random(input_shape)[np.newaxis,...]\n",
    "layer_outs = [func([test]) for func in functors]\n",
    "#print(layer_outs)\n",
    "print(layer_outs[0][0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1178 - accuracy: 0.9721 - categorical_accuracy: 0.0969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11782416701316833, 0.972100019454956, 0.09690000116825104]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 7850\n",
    "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
    "pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
    "print(pred.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpzmf5iyud/assets\n"
     ]
    }
   ],
   "source": [
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('modelno100.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
